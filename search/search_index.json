{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PGSync","text":"<p>PGSync keeps PostgreSQL/MySQL/MariaDB as your source of truth and publishes denormalized documents to Elasticsearch/OpenSearch\u2014continuously and transactionally.</p> <p> GitHub  PyPI  Docker</p>"},{"location":"#what-is-pgsync","title":"What is PGSync?","text":"<p>PGSync is a lightweight middleware that captures changes from PostgreSQL/MySQL/MariaDB and writes structured documents to your search cluster. Describe your document schema once (in JSON) and PGSync takes care of change capture, ordering, and delivery\u2014no custom ETL code.</p> <ul> <li>Transactionally consistent output (only committed writes; commit order preserved)</li> <li>Low overhead on PostgreSQL/MySQL/MariaDB </li> <li>Flexible mapping from relational data to nested documents</li> </ul>"},{"location":"advanced/re-indexing/","title":"Re indexing","text":"<p>Re-indexing involves:</p> <ul> <li>Deleting the Elasticsearch/OpenSearch index   <pre><code>curl -X DELETE &lt;protocol&gt;://&lt;hostname&gt;:&lt;port&gt;/&lt;index&gt;\n</code></pre></li> <li>Deleting the checkpoint file.   This is a hidden file which is a concatenation of the database name and the index name   <pre><code>rm .&lt;database name&gt;_&lt;index name&gt;\n</code></pre></li> <li>Then re-run pgsync   <pre><code>pgsync -c /path/to/schema.json\n</code></pre></li> </ul> <p>Info</p> <p>If any new tables were added or removed from the schema, you should re-run <code>bootstrap</code> first.</p>"},{"location":"command-args/","title":"Command arguments","text":"<p>PGSync supports the following command arguments </p> Command argument short form Description <code>--config</code> <code>-c</code> Path to the application schema config <code>--daemon</code> <code>-d</code> Flag to run pgsync as a daemon. Omit this to run in a single pass <code>--verbose</code> <code>-v</code> Turn on verbosity <code>--host</code> <code>-h</code> PG_HOST override <code>--password</code> Prompt for database password <code>--port</code> <code>-p</code> Prompt for database password <code>--user</code> <code>-u</code> PG_USER override <code>--version</code> Show version info <code>--analyze</code> <code>-a</code> Analyse database <code>--nthreads_polldb</code> <code>-n</code> Number of threads to spawn for poll db <code>--sslrootcert</code> PG_SSLROOTCERT override <code>--sslmode</code> PG_SSLMODE override (\"allow\", \"disable\", \"prefer\", \"require\", \"verify-ca\" or \"verify-full\") <code>--polling</code> Use polling mode <code>--bootstrap</code> <code>-b</code> First bootstrap before running pgsync process"},{"location":"env-vars/","title":"Environment variables","text":"<p>PGSync uses the dotenv module for reading a .env file. You can declare environment variables in a .env file located at the root of your application.</p> <p>Alternatively, you can set environment variables manually. e.g </p> <pre><code>$ export PG_USER=kermit\n$ export PG_HOST=localhost\n$ export PG_PORT=5432\n$ export PG_PASSWORD=******\n$ export ELASTICSEARCH_HOST=127.0.0.1\n$ export ELASTICSEARCH_PORT=9200\n$ pgsync -c schema.json\n</code></pre> Schema <pre><code>   {\n      \"table\": \"book\",\n      \"columns\": [\n          \"isbn\",\n          \"title\",\n          \"description\"\n      ],\n      \"children\": [\n          {\n              \"table\": \"author\",\n              \"columns\": [\n                  \"name\"\n              ]\n          }\n      ]\n  }\n</code></pre> SQL <pre><code>SELECT \n       JSON_BUILD_OBJECT(\n          'isbn', book_1.isbn, \n          'title', book_1.title, \n          'description', book_1.description,\n          'authors', anon_1.authors\n       ) AS \"JSON_BUILD_OBJECT_1\",\n       book_1.id\nFROM book AS book_1\nLEFT OUTER JOIN\n  (SELECT \n          JSON_AGG(anon_2.anon) AS authors,\n          book_author_1.book_isbn AS book_isbn\n   FROM book_author AS book_author_1\n   LEFT OUTER JOIN\n     (SELECT \n             author_1.name AS anon,\n             author_1.id AS id\n      FROM author AS author_1) AS anon_2 ON anon_2.id = book_author_1.author_id\n   GROUP BY book_author_1.book_isbn) AS anon_1 ON anon_1.book_isbn = book_1.isbn\n</code></pre> JSON <pre><code>  [\n      {\n          \"isbn\": \"9785811243570\",\n          \"title\": \"Charlie and the chocolate factory\",\n          \"description\": \"Willy Wonka\u2019s famous chocolate factory is opening at last!\",\n          \"authors\": [\"Roald Dahl\"]\n      },\n      {\n          \"isbn\": \"9788374950978\",\n          \"title\": \"Kafka on the Shore\",\n          \"description\": \"Kafka on the Shore is a 2002 novel by Japanese author Haruki Murakami\",\n          \"authors\": [\"Haruki Murakami\", \"Philip Gabriel\"]\n      },\n      {\n          \"isbn\": \"9781471331435\",\n          \"title\": \"1984\",\n          \"description\": \"1984 was George Orwell\u2019s chilling prophecy about the dystopian future\",\n          \"authors\": [\"George Orwell\"]\n      }\n  ]\n</code></pre> <p>PGSync provides the following environment variables:</p> Environment variable Default Description <code>SCHEMA</code> Path to the application schema config <code>CHECKPOINT_PATH</code> Path to store the checkpoint file <code>QUERY_CHUNK_SIZE</code> 10000 Database query chunk size (how many records to fetch at a time) <code>POLL_TIMEOUT</code> 0.1 Poll db interval (consider reducing this duration to increase throughput) <code>REPLICATION_SLOT_CLEANUP_INTERVAL</code> 180.0 Replication slot cleanup interval (in secs) <code>LOG_INTERVAL</code> 0.5 Stdout log interval (in secs) <code>NUM_WORKERS</code> 2 Number of workers to spawn for handling events <code>USE_ASYNC</code> False Enable experimental async mode <code>POLL_INTERVAL</code> 0.1 db polling interval for polling mode <code>ELASTICSEARCH_SCHEME</code> http Elasticsearch/OpenSearch protocol <code>ELASTICSEARCH_HOST</code> localhost Elasticsearch/OpenSearch host <code>ELASTICSEARCH_PORT</code> 9200 Elasticsearch/OpenSearch port <code>ELASTICSEARCH_USER</code> Elasticsearch/OpenSearch user <code>ELASTICSEARCH_PASSWORD</code> Elasticsearch/OpenSearch password <code>ELASTICSEARCH_TIMEOUT</code> 10 Increase this if you are getting read request timeouts <code>ELASTICSEARCH_CHUNK_SIZE</code> 2000 Elasticsearch/OpenSearch index chunk size (how many documents to index at a time) <code>ELASTICSEARCH_MAX_CHUNK_BYTES</code> 104857600 The maximum size of the Elasticsearch/OpenSearch request in bytes (default: 100MB) <code>ELASTICSEARCH_THREAD_COUNT</code> 4 The size of the threadpool to use for Elasticsearch/OpenSearch bulk requests <code>ELASTICSEARCH_QUEUE_SIZE</code> 4 The size of the task queue between the main thread (producing chunks to send) and the processing threads <code>ELASTICSEARCH_VERIFY_CERTS</code> True Verify Elasticsearch/OpenSearch SSL certificates <code>ELASTICSEARCH_USE_SSL</code> False Turn on SSL <code>ELASTICSEARCH_SSL_SHOW_WARN</code> False Show warnings about ssl certs verification <code>ELASTICSEARCH_CA_CERTS</code> Path to CA certs on disk <code>ELASTICSEARCH_CLIENT_CERT</code> PEM formatted SSL client certificate <code>ELASTICSEARCH_CLIENT_KEY</code> PEM formatted SSL client key <code>ELASTICSEARCH_AWS_REGION</code> Elasticsearch/OpenSearch AWS Region for fully managed services <code>ELASTICSEARCH_AWS_HOSTED</code> False Elasticsearch/OpenSearch fully managed service <code>ELASTICSEARCH_STREAMING_BULK</code> False Elasticsearch/OpenSearch streaming bulk index <code>ELASTICSEARCH_MAX_RETRIES</code> 0 The maximum number of times a document will be retried when <code>429</code> is received <code>ELASTICSEARCH_INITIAL_BACKOFF</code> 2 The number of seconds we should wait before the first retry <code>ELASTICSEARCH_MAX_BACKOFF</code> 600 The maximum number of seconds a retry will wait <code>ELASTICSEARCH_RAISE_ON_EXCEPTION</code> True if <code>False</code> then don't propagate exceptions from call to elasticsearch <code>ELASTICSEARCH_RAISE_ON_ERROR</code> True raise <code>BulkIndexError</code> containing errors (as <code>.errors</code>) from the execution of the last chunk when some occur <code>ELASTICSEARCH_API_KEY_ID</code> Elasticsearch/OpenSearch API Key ID <code>ELASTICSEARCH_API_KEY</code> Elasticsearch/OpenSearch API Key <code>PG_HOST</code> localhost Postgres database host <code>PG_USER</code> Postgres database username (superuser) <code>PG_PORT</code> 5432 Postgres database port <code>PG_PASSWORD</code> Postgres database user password <code>PG_SSLMODE</code> Postgres SSL TCP/IP connection mode ('disable', 'allow', 'prefer', 'require', 'verify-ca' or 'verify-full') <code>PG_SSLROOTCERT</code> The name of a file containing SSL certificate authority (CA) certificate(s) <code>PG_DRIVER</code> The database driver psycopg2 or pymysql <code>REDIS_CHECKPOINT</code> False Store checkpoint in redis/valkey instead of on filesystem <code>FORMAT_WITH_COMMAS</code> True Comma formatted logging <code>REDIS_SCHEME</code> redis Redis/Valkey connection scheme <code>REDIS_HOST</code> localhost Redis/Valkey server host <code>REDIS_PORT</code> 6379 Redis/Valkey server port <code>REDIS_DB</code> 0 Redis/Valkey database <code>REDIS_AUTH</code> Redis/Valkey password <code>REDIS_USER</code> Redis/Valkey username <code>REDIS_READ_CHUNK_SIZE</code> 1000 Number of items to read from Redis/Valkey at a time <code>REDIS_WRITE_CHUNK_SIZE</code> 1000 Number of items to write to Redis/Valkey at a time <code>REDIS_SOCKET_TIMEOUT</code> 5 Redis/Valkey socket connection timeout <code>REDIS_POLL_INTERVAL</code> 0.01 Redis/Valkey poll interval <code>NEW_RELIC_ENVIRONMENT</code> New Relic environment name <code>NEW_RELIC_APP_NAME</code> New Relic application name <code>NEW_RELIC_LOG_LEVEL</code> Sets the level of detail of messages sent to the log file <code>NEW_RELIC_LICENSE_KEY</code> New Relic license key <code>CONSOLE_LOGGING_HANDLER_MIN_LEVEL</code> CRITICAL, ERROR, WARNING, INFO or DEBUG <code>CUSTOM_LOGGING</code>"},{"location":"features/","title":"Features","text":"<p>PGSync focuses on reliability, low overhead, and clean documents for search.</p>"},{"location":"features/#highlights","title":"Highlights","text":"<ul> <li>PostgreSQL, MySQL, and MariaDB \u2014 works with any PostgreSQL (9.6+), MySQL (5.7+), or MariaDB (10.5+) database.</li> <li>Low overhead \u2014 negligible impact on database performance.</li> <li>Transactional consistency \u2014 only committed writes are indexed; inserts, updates, and deletes are applied in commit order.</li> <li>Fault tolerant &amp; resumable \u2014 no data loss on crashes or network interruptions; processing resumes from the last checkpoint.</li> <li>Native JSON path \u2014 returns data directly as PostgreSQL JSON for speed.</li> <li>Composite keys \u2014 supports composite primary and foreign keys.</li> <li>Deeply nested documents \u2014 supports arbitrary depth of related entities (tables with long chains of relationships).</li> <li>JSON field extraction \u2014 extract JSON fields from a table into separate fields in the resulting document.</li> <li>Customizable document structure \u2014 tailor documents to your index and query needs.</li> </ul>"},{"location":"features/#details","title":"Details","text":""},{"location":"features/#consistency","title":"Consistency","text":"<ul> <li>Only committed transactions appear in Elasticsearch/OpenSearch.</li> <li>Operation order (insert \u2192 update \u2192 delete) is preserved based on commit order.</li> </ul>"},{"location":"features/#reliability","title":"Reliability","text":"<ul> <li>Designed to avoid data loss if a process crashes or the network drops.</li> <li>Recovery resumes from the last successful checkpoint.</li> </ul>"},{"location":"features/#data-modeling","title":"Data modeling","text":"<ul> <li>Composite primary and foreign keys supported.</li> <li>Arbitrary-depth relationships (one-to-one, one-to-many, through tables).</li> <li>Extract and map PostgreSQL JSON fields to top-level document fields.</li> </ul>"},{"location":"features/#performance","title":"Performance","text":"<ul> <li>Builds documents directly from PostgreSQL JSON to minimize transformation overhead.</li> </ul>"},{"location":"features/#compatibility","title":"Compatibility","text":"<ul> <li> PostgreSQL 9.6+ or later</li> <li> MySQL 8.0+ or later</li> <li> MariaDB 10.3+ or later</li> <li> Elasticsearch 6.3.1+</li> <li> OpenSearch 1.3.7+</li> </ul>"},{"location":"getting-started/docker/","title":"Docker","text":"<p>First, you need to bootstrap the database.</p>"},{"location":"getting-started/docker/#running-with-docker-using-image-repository","title":"Running with Docker (Using Image Repository)","text":"<p>To start all services with Docker, follow these steps:</p> <ol> <li>Pull the Docker image:</li> </ol> <pre><code>$ docker pull toluaina1/pgsync:latest\n</code></pre> <ol> <li>Run the container:</li> </ol> <pre><code>$ docker run --rm -it \\\n-e REDIS_CHECKPOINT=true \\\n-e REDIS_HOST=&lt;redis_host_address&gt; \\\n-e PG_URL=postgres://&lt;username&gt;:&lt;password&gt;@&lt;postgres_host&gt;/&lt;database&gt; \\\n-e ELASTICSEARCH_URL=http://&lt;elasticsearch_host&gt;:9200 \\\n-v \"$(pwd)/schema.json:/app/schema.json\" \\\ntoluaina1/pgsync:latest -c schema.json -d -b\n</code></pre> <p>Environment variable placeholders - full list here:</p> <ul> <li>redis_host_address \u2014 Address of the Redis/Valkey server (e.g., host.docker.internal for local Docker setup)</li> <li>username \u2014 PostgreSQL username</li> <li>password \u2014 PostgreSQL password</li> <li>postgres_host \u2014 Host address for PostgreSQL instance (e.g., host.docker.internal)</li> <li>database \u2014 Name of PostgreSQL database</li> <li>elasticsearch_host \u2014 Address of Elasticsearch/OpenSearch instance (e.g., host.docker).</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<pre><code>$ pip install pgsync\n\n---&gt; 100%\n</code></pre>"},{"location":"getting-started/running/","title":"Running","text":"<p>First, you need to bootstrap the database.</p> <p>This is a one-time operation that:</p> <ul> <li>Creates pgsync triggers</li> <li>Creates the logical replication slot</li> </ul> <pre><code>bootstrap --config /path/to/schema.json\n</code></pre> <p>There are two modes of running PGSync</p> <ul> <li>Daemon mode (runs continuously)</li> <li>Non-daemon mode (runs a single pass and stops)</li> </ul> DaemonNon-daemon <pre><code>pgsync --config /path/to/schema.json --daemon\n</code></pre> <pre><code>pgsync --config /path/to/schema.json\n</code></pre> <p>Info</p> <p>You can also specify the schema config as an environment variable SCHEMA and omit it in the command(s) above. The next section describes how to provide connection parameters via environment variables.</p>"},{"location":"getting-started/setup/","title":"Setup","text":"Self HostedAWS <ul> <li>Ensure Postgres database user is a superuser (this is required to query replication slots)   <pre><code> SELECT usename FROM pg_user WHERE usesuper = true\n</code></pre></li> <li>Enable logical decoding in postgres.conf</li> </ul> <pre><code>wal_level = logical\n</code></pre> <ul> <li>Ensure there is at least one replication slot defined in postgres.conf <pre><code>max_replication_slots = 1\n</code></pre></li> </ul> <ul> <li>Ensure Postgres database user is a superuser <pre><code>GRANT rds_superuser TO &lt;username&gt;\n</code></pre></li> <li>Enable logical_replication by using the parameter group settings described here</li> </ul> <p>Info</p> <p>To prevent your server logs from growing too large e.g when running on cloud infrastructure where there is a cost implication. You can optionally impose a ceiling on the replication slot size using max_slot_wal_keep_size</p> <p><code>max_slot_wal_keep_size = 100GB</code></p>"},{"location":"license/","title":"License","text":"<p>MIT License \u2014 a short, permissive license that allows commercial use, modification, distribution, private use, and sublicensing.</p> <p>TL;DR (not legal advice)</p> <ul> <li>You can use, copy, modify, merge, publish, distribute, sublicense, and sell copies.</li> <li>You must keep the copyright notice and this permission notice in all copies.</li> <li>No warranty. The software is provided as is; authors are not liable.</li> </ul> <p>Copy-paste headers for your source files</p> <pre><code>SPDX-License-Identifier: MIT\nCopyright (c) 2016\u20132025 Tolu Aina\n</code></pre> Full text (authoritative) <pre><code>MIT License\n\nCopyright \u00a9 2016-2025 Tolu Aina\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"requirements/","title":"Requirements","text":"<p>PGSync has a small set of runtime dependencies. Versions shown are minimum supported.</p>"},{"location":"requirements/#minimum-versions","title":"Minimum versions","text":"Component Version (min) Notes Python 3.9+ Use a virtual environment for isolation. PostgreSQL or MySQL or MariaDB PostgreSQL 12+ \u2022 MySQL 5.7+ \u2022 MariaDB 10.5+ Use any one SQL database. Network access required; JSON/JSONB support recommended. Redis or Valkey Redis 3.1.0+ or Valkey 7.2.0+ Choose one key-value store. Elasticsearch or OpenSearch Elasticsearch 6.3.1+ or OpenSearch 1.3.7+ Choose one search backend. SQLAlchemy (Python) 1.3.4+ Installed as a Python dependency."},{"location":"requirements/#select-your-database-driver","title":"Select your database driver","text":"PostgreSQL MariaDB /  MySQL <p>Set the driver to psycopg2.</p> <pre><code>export PG_DRIVER=psycopg2\n# Windows (PowerShell):\n# $env:PG_DRIVER = \"psycopg2\"\n</code></pre> <p>Quick check <pre><code>import os\nprint(\"PG_DRIVER =\", os.getenv(\"PG_DRIVER\"))\nimport psycopg2\nprint(\"psycopg2 import OK\")\n</code></pre></p> <p>Set the driver to PyMySQL.</p> <pre><code>export PG_DRIVER=pymysql\n# Windows (PowerShell):\n# $env:PG_DRIVER = \"pymysql\"\n</code></pre> <p>Quick check <pre><code>import os\nprint(\"PG_DRIVER =\", os.getenv(\"PG_DRIVER\"))\nimport pymysql\nprint(\"PyMySQL import OK\")\n</code></pre></p> <p>Tip</p> <p>This only selects the Python DB driver; your connection URL/envs stay the same. Supported databases: PostgreSQL 9.6+, MySQL 8.0+, MariaDB 10.3+.</p>"},{"location":"requirements/#choose-your-search-backend","title":"Choose your search backend","text":"Elasticsearch OpenSearch <ul> <li>Version 6.3.1+</li> <li>Ensure the cluster is reachable from where PGSync runs.</li> </ul> <p>Quick check <pre><code>curl -s http://localhost:9200 | jq .\n# or\nelasticsearch --version\n</code></pre></p> <ul> <li>Version 1.3.7+</li> <li>Ensure the cluster is reachable from where PGSync runs.</li> </ul> <p>Quick check <pre><code>curl -s http://localhost:9200 | jq .\n# or\nopensearch --version\n</code></pre></p>"},{"location":"requirements/#quick-checks","title":"Quick checks","text":"<p>Verify the basics on the host that will run PGSync:</p> <pre><code>python3 --version\npsql --version\nredis-cli --version      # or: valkey-cli --version\n</code></pre>"},{"location":"scaling/multiple-workers/","title":"Multiple workers","text":"<p>Increasing throughput with multiple consumers.</p> <p>You can increase throughput by running one or more consumers for the same target schema.</p> <p>How it works:</p> <ol> <li> <p>First, run a single producer process: <pre><code>pgsync -c schema.json --producer\n</code></pre></p> </li> <li> <p>Then, run one or more consumer processes (each in a separate process or machine):</p> </li> </ol> <pre><code>pgsync -c schema.json --consumer\npgsync -c schema.json --consumer\npgsync -c schema.json --consumer\n</code></pre> <p>This setup allows multiple consumers to work in parallel, improving overall throughput.</p> <p>Additionally, you can increase the number of workers used for handling requests.</p> <pre><code>pgsync -c schema.json -n 4\npgsync -c schema.json --consumer -n 6\n</code></pre> <p>Info</p> <p>The -n argument does not apply in the producer only mode. i.e with: <code>pgsync -c schema.json --producer</code></p>"},{"location":"scaling/parallel-sync/","title":"Parallel sync","text":"<p>Parallel Sync</p> <p>Parallel Sync is a feature designed to significantly improve sync speed by utilizing multiple CPUs/threads. It is particularly useful in environments with high network latency, where PostgreSQL, Elasticsearch/OpenSearch, and PGSync servers run on different networks.</p> <p>Why Use Parallel Sync?</p> <p>In distributed setups, slow request/response times especially during database queries can limit sync performance. Even with server side cursors, delays in fetching the next batch of records can bottleneck the process.</p> <p>Parallel Sync addresses this by running an initial high speed, parallel sync to populate Elasticsearch/OpenSearch in one iteration. After this, a regular PGSync process can continue to run as a daemon for ongoing sync.</p> <p>How It Works:</p> <p>PGSync leverages PostgreSQL's internal ctid system column, which uniquely identifies rows based on their position in a table (page and row number).</p> <p>The sync process paginates records using ctid, distributing work evenly across available CPUs/threads.</p> <p>Each worker thread processes a \"chunk\" of data in parallel, using efficient filtered queries based on page and row numbers.</p> <p>Bulk inserts to Elasticsearch/OpenSearch are executed concurrently, maximizing throughput.</p> <p>Parallel Sync Execution Modes</p> <p>Parallel Sync supports multiple execution modes to match your system's architecture and performance needs.</p> <pre><code>parallel_sync -c schema.json -m multiprocess\n</code></pre> <p>Available Modes:</p> <ul> <li> <p>synchronous \u2014 Runs in a single threaded, sequential mode (baseline behavior).</p> </li> <li> <p>multithreaded \u2014 Uses multiple threads within a single process for parallel sync.</p> </li> <li> <p>multiprocess \u2014 Spawns multiple processes to perform sync in parallel.</p> </li> <li> <p>multithreaded_async \u2014 Combines multithreading with asynchronous I/O for improved concurrency.</p> </li> <li> <p>multiprocess_async \u2014 Combines multiple processes with asynchronous I/O for maximum parallelism and efficiency.</p> </li> </ul>"},{"location":"schema/","title":"Schema definition","text":"<p>Schema definition file</p> <pre><code>[\n    {\n        \"database\": \"&lt;Postgres database name&gt;\",\n        \"index\": \"&lt;Elasticsearch/OpenSearch index name&gt;\",\n        \"setting\": \"&lt;Elasticsearch/OpenSearch setting&gt;\",\n        \"plugins\": [\"&lt;Plugin A&gt;\", \"&lt;Plugin B&gt;\"...],\n        \"pipeline\": \"&lt;pipeline&gt;\",\n        \"routing\": \"&lt;routing&gt;\",\n        \"nodes\": {\n            \"table\": \"&lt;root table name&gt;\",\n            \"schema\": \"&lt;schema name&gt;\",\n            \"columns\": [\n                \"&lt;column 1&gt;\",\n                \"&lt;column 2&gt;\",\n                ...\n            ],\n            \"children\": [\n                {\n                    \"table\": \"&lt;child table name&gt;\",\n                    \"columns\": [\n                        \"&lt;column 1&gt;\",\n                        \"&lt;column 2&gt;\",\n                        ...\n                    ],\n                    \"label\": \"&lt;document label name&gt;\",\n                    \"relationship\": {\n                        \"variant\": \"object\" | \"scalar\",\n                        \"type\": \"one_to_one\" | \"one_to_many\",\n                        \"through_tables\": [\n                            \"&lt;through table name&gt;\"\n                        ]\n                    },\n                    \"children\": [],\n                    \"transform\": {\n                        \"rename\": {\n                            \"&lt;old column 1&gt;\": \"&lt;new column 1&gt;\",\n                            \"&lt;old column 2&gt;\": \"&lt;new column 2&gt;\",\n                            ...\n                        },\n                        \"mapping\": {\n                            \"&lt;new column 1&gt;\": {\"&lt;data type&gt;\"},\n                            \"&lt;new column 2&gt;\": {\"&lt;data type&gt;\"},\n                            ...\n                        },\n                        \"concat\": {\n                            \"columns\": [\"column 1\", \"column 2\" ...],\n                            \"destination\": \"&lt;new column 1&gt;\",\n                            \"delimiter\": \"&lt;char&gt;\"\n                        }\n                    }\n                },\n                ...\n            ]\n        }\n    }\n]\n</code></pre>"},{"location":"schema/#document-and-node-structure","title":"Document and node structure:","text":""},{"location":"schema/#database","title":"<code>database</code>","text":"<p>This is the database name</p>"},{"location":"schema/#index","title":"<code>index</code>","text":"<p>An optional Elasticsearch/OpenSearch index (defaults to database name)</p>"},{"location":"schema/#nodes","title":"<code>nodes</code>","text":"<p>An object node describing the Elasticsearch/OpenSearch document</p>"},{"location":"schema/#setting","title":"<code>setting</code>","text":"<p>Elasticsearch/OpenSearch setting configuration     <pre><code>{\n    \"setting\": {\n        \"analysis\": {\n            \"analyzer\": {\n                \"ngram_analyzer\": {\n                    \"filter\": [\n                        \"lowercase\"\n                    ],\n                    \"type\": \"custom\",\n                    \"tokenizer\": \"ngram_tokenizer\"\n                }\n            },\n            \"tokenizer\": {\n                \"ngram_tokenizer\": {\n                    \"token_chars\": [\n                        \"letter\",\n                        \"digit\",\n                        \"punctuation\",\n                        \"symbol\"\n                    ],\n                    \"min_gram\": \"9\",\n                    \"type\": \"nGram\",\n                    \"max_gram\": \"10\"\n                }\n            }\n        }\n    }\n}\n</code></pre></p>"},{"location":"schema/#table","title":"<code>table</code>","text":"<p>Node table name</p>"},{"location":"schema/#schema","title":"<code>schema</code>","text":"<p>An optional Postgres table schema (defaults to public)</p>"},{"location":"schema/#label","title":"<code>label</code>","text":"<p>An optional node name in Elasticsearch/OpenSearch (defaults to table name)</p>"},{"location":"schema/#columns","title":"<code>columns</code>","text":"<p>An optional list of columns to display. This can be omitted in which case it selects all columns.</p>"},{"location":"schema/#children","title":"<code>children</code>","text":"<p>An optional list of child nodes if any. This has the same structure as a parent node.</p>"},{"location":"schema/#relationship","title":"<code>relationship</code>","text":"<p>Describes the relationship between parent and child.</p>"},{"location":"schema/#variant","title":"<code>variant</code>","text":"variant can be <code>object</code> or <code>scalar</code>"},{"location":"schema/#object","title":"<code>object</code>","text":"<pre><code>{\n    \"name\": \"Oxford Press\",\n    \"id\": 1,\n    \"is_active\": false\n}\n</code></pre>"},{"location":"schema/#scalar","title":"<code>scalar</code>","text":"<pre><code>[\"Haruki Murakami\", \"Philip Gabriel\"]\n</code></pre>"},{"location":"schema/#type","title":"<code>type</code>","text":"<p>type can be <code>one_to_one</code> or <code>one_to_many</code> depending on the relationship type between  parent and child</p>"},{"location":"schema/#through_tables","title":"<code>through_tables</code>","text":"<p>This is the intermediate table that connects the parent to the child</p>"},{"location":"schema/#transform","title":"<code>transform</code>","text":"<p>This allows transforming some node properties. For now, the only operation supported is the <code>rename</code> transform.</p>"},{"location":"schema/#rename","title":"<code>rename</code>","text":"rename a node column<pre><code>    \"rename\": {\n        \"&lt;old column name 1&gt;\": \"&lt;new column name 1&gt;\",\n        \"&lt;old column name 2&gt;\": \"&lt;new column name 2&gt;\",\n    }\n</code></pre>"},{"location":"schema/#mapping","title":"<code>mapping</code>","text":"<p>Specify Elasticsearch/OpenSearch mapping</p> <pre><code>    \"mapping\": {\n         \"book_id\": {\n            \"type\": \"long\"\n        },\n        \"book_isbn\": {\n            \"type\": \"long\",\n            \"fields\":{\n                \"ngram\": {\n                    \"type\": \"text\",\n                    \"analyzer\": \"ngram_analyzer\",\n                    \"search_analyzer\": \"ngram_analyzer\",\n                    \"fielddata\": true\n                }\n            }\n        }\n    }\n</code></pre>"},{"location":"schema/#pipeline","title":"<code>pipeline</code>","text":"<p>Optional injest pipeline</p>"},{"location":"schema/#routing","title":"<code>routing</code>","text":"<p>Optional routing field</p> <p>Info</p> <p>Changing the schema effectively changes the structure of the document in Elasticsearch/OpenSearch  and this requires re-indexing Elasticsearch/OpenSearch.</p> <p>See the advanced section on re-indexing on how-to.</p>"},{"location":"tutorial/json-fields/","title":"Json fields","text":"<p>PGSync supports Postgres JSON and JSONB operators. This allows you to extract data within JSON fields.</p> <p>These operators are defined here</p> <p>For example. Given a Postgres JSON field called <code>doc</code></p> <pre><code>{\n    \"a\": {\n        \"b\": {\n            \"c\": [0, 1, 2, 3, 4]\n        }\n    },\n    \"x\": [\n        {\n            \"y\": 0,\n            \"z\": 5\n        },\n        {\n            \"y\": 1,\n            \"z\": 6\n        }\n    ]\n}\n</code></pre> <p>We can define this JSON schema to extract the fourth element of the  <code>{a, b, c}</code> path, we can define this schema</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"schema\": \"my_book_library\",\n            \"columns\": [\n                \"doc#&gt;{a,b,c}-&gt;4\"\n            ]\n        }\n    }\n]\n</code></pre> <p>We can define this JSON schema, to get the first array element of field <code>x</code>.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"schema\": \"my_book_library\",\n            \"columns\": [\n                \"doc-&gt;x-&gt;0\"\n            ]\n        }\n    }\n]\n</code></pre> <p>Info</p> <p><code>doc</code> is the field name in the database</p>"},{"location":"tutorial/multiple-schemas-in-single-config/","title":"Multiple schemas in single config","text":"<p>We can declare multiple schemas in the same config.  This can be useful for syncing multiple tables into different Elasticsearch/OpenSearch indices.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book_index\",\n        \"nodes\": {\n            \"table\": \"book\"\n        }\n    },\n    {\n        \"database\": \"book\",\n        \"index\": \"author_index\",\n        \"nodes\": {\n            \"table\": \"author\"\n        }\n    }\n]\n</code></pre>"},{"location":"tutorial/plugins/","title":"Plugins","text":"<p>Plugins allow you to alter a document right before indexing.</p> <p>This can be useful for applying transformations to documents  and offers greater flexibility.</p> <p>Although this comes with some level of development.</p> <p>Plugins are currently supported only in the Python Language.</p> <p>For example, imagine you had a user profile database with <code>firstname</code> and  <code>lastname</code> fields and generating the Elasticsearch/OpenSearch doc below.</p> <pre><code>{\n    \"firstname\": \"feng\",\n    \"lastname\": \"shui\"\n}\n</code></pre> <p>we can create a plugin to add a <code>fullname</code> field to the document  right before indexing. </p> <p>Create a \"plugins\" directory and add it to your <code>PYTHONPATH</code>.</p> <p>The <code>PYTHONPATH</code> should contain the path to the \"plugins\" directory excluding  the \"plugins\" directory itself.</p> <p>e.g:</p> <p><code>export PYTHONPATH=$PYTHONPATH:/path/to/myplugindir</code></p> <p>Make sure you have created an empty init module inside the \"plugins\" directory i.e <code>plugins/__init__.py</code></p> <p>Create a plugin module - fullnameplugin.py inside the \"plugins\" directory and  add the code below:</p> <pre><code>from pgsync import plugin\n\n\nclass FullnamePlugin(plugin.Plugin):\n    name = 'Fullname'\n\n    def transform(self, doc, **kwargs):\n\n        firstname = doc['firstname'] \n        lastname = doc['lastname'] \n        doc['fullname'] = f'{firstname}{lastname}'\n\n        return doc\n</code></pre> <p>Your plugins directory layout should look like this:</p> <ul> <li><code>plugins/fullnameplugin.py</code></li> <li><code>plugins/__init__.py</code></li> </ul> <p>Then simply activate the plugin by adding it to the list of plugins in the schema.json</p> <pre><code>[\n    {\n        \"database\": \"users\",\n        \"index\": \"users\",\n        \"plugins\": [\"Fullname\"],\n        \"nodes\": {\n            \"table\": \"profile\"\n        }\n    }\n]\n</code></pre> <p>To get this document in Elasticsearch/OpenSearch</p> <pre><code>{\n    \"firstname\": \"feng\",\n    \"lastname\": \"shui\",\n    \"fullname\": \"feng shui\"\n}\n</code></pre> <p>Info</p> <p>Plugin names are case sensitive</p>"},{"location":"tutorial/relationship-with-object-variant/","title":"Relationship with object variant","text":"<p>Each child node can have only one direct parent.</p> <p>You can specify the relationship between a parent and child node using the <code>relationship</code> property.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"id\",\n                        \"name\"\n                    ],\n                    \"relationship\": {\n                        \"variant\": \"object\",\n                        \"type\": \"one_to_one\"\n                    },\n                }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"publisher\": {\n          \"id\": 1,\n          \"name\": \"Oxford Press\"\n      }\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"publisher\": {\n          \"id\": 2,\n          \"name\": \"Penguin Books\"\n      }\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"publisher\": {\n          \"id\": 3,\n          \"name\": \"Pearson Press\"\n      }\n  }\n]\n</code></pre> <p>Info</p> <p>A relationship must include both a <code>variant</code> and a <code>type</code> attribute</p>"},{"location":"tutorial/relationship-with-one-to-many-type/","title":"Relationship with one to many type","text":"<p>Each child node can have only one direct parent.</p> <p>We can specify the relationship between a parent and child node using the <code>relationship</code> property.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"id\",\n                        \"name\"\n                    ],\n                    \"relationship\": {\n                        \"variant\": \"object\",\n                        \"type\": \"one_to_many\"\n                    },\n                }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"publisher\": [\n          {\n            \"id\": 1,\n            \"name\": \"Oxford Press\"\n          }\n       ]\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"publisher\": [\n          {\n            \"id\": 2,\n            \"name\": \"Penguin Books\"\n          }\n       ]\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"publisher\": [\n          {\n            \"id\": 3,\n            \"name\": \"Pearson Press\"\n          }\n       ]\n  }\n]\n</code></pre> <p>Info</p> <p>A relationship must include both a <code>variant</code> and a <code>type</code> attribute</p>"},{"location":"tutorial/relationship-with-one-to-one-type/","title":"Relationship with one to one type","text":"<p>Each child node can have only one direct parent.</p> <p>We can specify the relationship between a parent and child node using the <code>relationship</code> property.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"id\",\n                        \"name\"\n                    ],\n                    \"relationship\": {\n                        \"variant\": \"object\",\n                        \"type\": \"one_to_one\"\n                    },\n                }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"publisher\": {\n          \"id\": 1,\n          \"name\": \"Oxford Press\"\n      }\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"publisher\": {\n          \"id\": 2,\n          \"name\": \"Penguin Books\"\n      }\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"publisher\": {\n          \"id\": 3,\n          \"name\": \"Pearson Press\"\n      }\n  }\n]\n</code></pre> <p>Info</p> <p>A relationship must include both a <code>variant</code> and a <code>type</code> attribute</p>"},{"location":"tutorial/relationship-with-scalar-variant/","title":"Relationship with scalar variant","text":"<p>Each child node can have only one direct parent.</p> <p>You can specify the relationship between a parent and child node using the <code>relationship</code> property.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"name\"\n                    ],\n                    \"relationship\": {\n                        \"variant\": \"scalar\",\n                        \"type\": \"one_to_one\"\n                    },\n                }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"publisher\": \"Oxford Press\"\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"publisher\": \"Penguin Books\"\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"publisher\":  \"Pearson Press\"\n  }\n]\n</code></pre> <p>Info</p> <p>A relationship must include both a <code>variant</code> and a <code>type</code> attribute</p>"},{"location":"tutorial/relationship-with-through-tables/","title":"Relationship with through tables","text":"<p>Each child node can have only one direct parent.</p> <p>We can specify the relationship between a parent and child node using the <code>relationship</code> property.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"columns\": [\n                \"isbn\",\n                \"title\",\n                \"description\"\n            ],\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"id\", \"name\"\n                    ],\n                    \"relationship\": {\n                        \"type\": \"one_to_many\",\n                        \"variant\": \"object\",\n                        \"through_tables\": [\n                            \"book_author\"\n                        ]\n                    }\n                 }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"author\": [\n          {\n            \"id\": 1,\n            \"name\": \"Roald Dahl\"\n          }\n       ]\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"author\": [\n          {\n            \"id\": 2,\n            \"name\": \"Haruki Murakami\"\n          },\n          {\n            \"id\": 3,\n            \"name\": \"Philip Gabriel\"\n          }\n       ]\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"author\": [\n          {\n            \"id\": 4,\n            \"name\": \"George Orwell\"\n          }\n       ]\n  }\n]\n</code></pre> <p>Info</p> <p>A relationship must include both a <code>variant</code> and a <code>type</code> attribute</p>"},{"location":"tutorial/relationship-with-user-defined-foreign-key/","title":"Relationship with user defined foreign key","text":"<p>You can specify the relationship foreign key as a property on the <code>relationship</code>.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"id\",\n                        \"name\"\n                    ],\n                    \"relationship\": {\n                        \"variant\": \"object\",\n                        \"type\": \"one_to_one\",\n                        \"foreign_key\": {\n                            \"child\": [\"id\"],\n                            \"parent\": [\"parent_id\"]\n                        }\n                    },\n                }\n            ]\n        }\n    }\n]\n</code></pre>"},{"location":"tutorial/selecting-schema/","title":"Selecting schema","text":"<p>Postgres supports having multiple schemas in the same database.</p> <p>You can select an alternative schema using the node <code>schema</code> attribute.</p> <p>The default schema is the <code>public</code> schema.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"schema\": \"my_book_library\",\n            \"columns\": [\n                \"isbn\",\n                \"title\"\n            ]\n        }\n    }\n]\n</code></pre>"},{"location":"tutorial/table-with-multiple-children/","title":"Table with multiple children","text":"<p>What if we added a new table <code>publisher</code></p> <p>Publisher</p> id (PK) name 1 Oxford Press 2 Penguin Books 3 Pearson Press <p>and we added <code>publisher_id</code> as a foreign key to the Book table:</p> <p>Book</p> isbn (PK) title description publisher_id (FK) 9785811243570 Charlie and the chocolate factory Willy Wonka\u2019s famous chocolate factory is opening at last! 1 9788374950978 Kafka on the Shore Kafka on the Shore is a 2002 novel by Japanese author Haruki Murakami. 2 9781471331435 1984 1984 was George Orwell\u2019s chilling prophecy about the dystopian future. 3 <p>We can simply define this JSON schema where the book table is still the pivot table.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"columns\": [\n                \"isbn\",\n                \"title\",\n                \"description\"\n            ],\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"name\"\n                    ]\n                },\n                {\n                    \"table\": \"publisher\",\n                    \"columns\": [\n                        \"name\",\n                        \"id\"\n                    ]\n                }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"description\": \"Willy Wonka\u2019s famous chocolate factory is opening at last!\",\n      \"author\": [\"Roald Dahl\"],\n      \"publisher\": \"Oxford Press\"\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"description\": \"Kafka on the Shore is a 2002 novel by Japanese author Haruki Murakami\",\n      \"author\": [\"Haruki Murakami\", \"Philip Gabriel\"],\n      \"publisher\": \"Penguin Books\"\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"description\": \"1984 was George Orwell\u2019s chilling prophecy about the dystopian future\",\n      \"author\": [\"George Orwell\"],\n      \"publisher\": \"Pearson Press\"\n  }\n]\n</code></pre>"},{"location":"tutorial/table-with-single-child-node/","title":"Table with single child node","text":"<p>Consider this example of a Book library database.</p> <p>Book</p> isbn (PK) title description 9785811243570 Charlie and the chocolate factory Willy Wonka\u2019s famous chocolate factory is opening at last! 9788374950978 Kafka on the Shore Kafka on the Shore is a 2002 novel by Japanese author Haruki Murakami. 9781471331435 1984 1984 was George Orwell\u2019s chilling prophecy about the dystopian future. <p>Author</p> id (PK) name 1 Roald Dahl 2 Haruki Murakami 3 Philip Gabriel 4 George Orwell <p>BookAuthor</p> id (PK) book_isbn (FK) author_id (FK) 1 9785811243570 1 2 9788374950978 2 3 9788374950978 3 4 9781471331435 4 <p>With PGSync, we can simply define this JSON schema where the book table is the pivot. A pivot table indicates the root of your document.</p> <pre><code>{\n    \"table\": \"book\",\n    \"columns\": [\n        \"isbn\",\n        \"title\",\n        \"description\"\n    ],\n    \"children\": [\n        {\n            \"table\": \"author\",\n            \"columns\": [\n                \"name\"\n            ]\n        }\n    ]\n}\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"description\": \"Willy Wonka\u2019s famous chocolate factory is opening at last!\",\n      \"author\": [\"Roald Dahl\"]\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"description\": \"Kafka on the Shore is a 2002 novel by Japanese author Haruki Murakami\",\n      \"author\": [\"Haruki Murakami\", \"Philip Gabriel\"]\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"description\": \"1984 was George Orwell\u2019s chilling prophecy about the dystopian future\",\n      \"author\": [\"George Orwell\"]\n  }\n]\n</code></pre> <p>Behind the scenes, PGSync is generating advanced queries for you such as.</p> <pre><code>SELECT \n       JSON_BUILD_OBJECT(\n          'isbn', book_1.isbn, \n          'title', book_1.title, \n          'description', book_1.description,\n          'authors', anon_1.authors\n       ) AS \"JSON_BUILD_OBJECT_1\",\n       book_1.id\nFROM book AS book_1\nLEFT OUTER JOIN\n  (SELECT \n          JSON_AGG(anon_2.anon) AS authors,\n          book_author_1.book_isbn AS book_isbn\n   FROM book_author AS book_author_1\n   LEFT OUTER JOIN\n     (SELECT \n             author_1.name AS anon,\n             author_1.id AS id\n      FROM author AS author_1) AS anon_2 ON anon_2.id = book_author_1.author_id\n   GROUP BY book_author_1.book_isbn) AS anon_1 ON anon_1.book_isbn = book_1.isbn\n</code></pre>"},{"location":"tutorial/transform-nodes/","title":"Transform nodes","text":"<p>Transform nodes allow you to change the output of the document type</p>"},{"location":"tutorial/transform-nodes/#rename","title":"<code>rename</code>","text":"<p>We can simply define this JSON schema.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"columns\": [\n                \"isbn\",\n                \"title\"\n            ],\n            \"transform\": {\n                \"rename\": {\n                    \"isbn\": \"book_isbn\",\n                    \"title\": \"book_title\"\n                }\n            }\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n    {\n        \"book_isbn\": \"9785811243570\",\n        \"book_title\": \"Charlie and the chocolate factory\"\n    },\n    {\n        \"book_isbn\": \"9788374950978\",\n        \"book_title\": \"Kafka on the Shore\"\n    },\n    {\n        \"book_isbn\": \"9781471331435\",\n        \"book_title\": \"1984\"\n    }\n]\n</code></pre>"},{"location":"tutorial/transform-nodes/#mapping","title":"<code>mapping</code>","text":"<p>You can specify the data type for an Elasticsearch/OpenSearch field in the schema.</p> <p>You can find the list of supported data types here</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"node\": {\n            \"table\": \"book\",\n            \"columns\": [\n                \"isbn\",\n                \"title\"\n            ],\n            \"transform\": {\n                \"mapping\": {\n                    \"id\": {\n                        \"type\": \"long\"\n                    },\n                    \"isbn\": {\n                        \"type\": \"long\"\n                    },\n                    \"title\": {\n                        \"type\": \"keyword\"\n                    }\n                }\n            }\n        }\n    }\n]\n</code></pre>"},{"location":"tutorial/transform-nodes/#concat","title":"<code>concat</code>","text":"<p>You can concatenate multiple columns into a single field with an optional delimiter.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"node\": {\n            \"table\": \"book\",\n            \"columns\": [\n                \"title\",\n                \"firstname\",\n                \"lastname\"\n            ],\n            \"transform\": {\n                \"concat\": {\n                    \"columns\": [\"title\", \"firstname\", \"lastname\"],\n                    \"destination\": \"fullname\",\n                    \"delimiter\": \"-\"\n                }\n            }\n        }\n    }\n]\n</code></pre>"},{"location":"tutorial/using-labels/","title":"Using labels","text":"<p>Labels are used to control the output of the document node.</p> <p>We can simply define this JSON schema.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"columns\": [\n                \"isbn\",\n                \"title\"\n            ],\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"label\": \"authors\",\n                    \"columns\": [\n                        \"name\"\n                    ]\n                }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"authors\": [\"Roald Dahl\"]\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"authors\": [\"Haruki Murakami\", \"Philip Gabriel\"]\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"authors\": [\"George Orwell\"]\n  }\n]\n</code></pre>"}]}