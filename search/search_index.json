{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PGSync","text":"<p>Real-time data synchronization from PostgreSQL, MySQL, and MariaDB to Elasticsearch and OpenSearch\u2014continuously and transactionally.</p> <p> Get Started  GitHub  PyPI  Docker  DigitalOcean Marketplace</p>"},{"location":"#what-is-pgsync","title":"What is PGSync?","text":"<p>PGSync is a lightweight middleware that captures changes from your relational database and writes structured, denormalized documents to your search cluster.</p> <p>Define your document schema once in JSON, and PGSync handles change capture, ordering, and delivery automatically\u2014no custom ETL code required.</p> <ul> <li> Change Data Capture \u2014 Automatically captures INSERT, UPDATE, and DELETE using logical replication</li> <li> Low Overhead \u2014 Minimal impact on database performance</li> <li> Fault Tolerant \u2014 Resumes from last checkpoint after crashes</li> <li> Nested Documents \u2014 Transform relational data into deeply nested JSON</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>pip install pgsync\n</code></pre> <pre><code>{\n  \"database\": \"mydb\",\n  \"index\": \"books\",\n  \"nodes\": {\n    \"table\": \"book\",\n    \"children\": [{ \"table\": \"author\" }]\n  }\n}\n</code></pre> <pre><code>pgsync --config schema.json --daemon\n</code></pre> <p>PGSync is supported by DigitalOcean.</p> <p> </p>"},{"location":"advanced/re-indexing/","title":"Re-indexing","text":"<p>Re-indexing rebuilds your Elasticsearch/OpenSearch index from scratch. Follow these steps:</p> <p>1. Delete the Elasticsearch/OpenSearch index:</p> <pre><code>curl -X DELETE &lt;protocol&gt;://&lt;hostname&gt;:&lt;port&gt;/&lt;index&gt;\n</code></pre> <p>2. Delete the checkpoint file:</p> <p>The checkpoint is a hidden file named as a concatenation of the database name and index name:</p> <pre><code>rm .&lt;database_name&gt;_&lt;index_name&gt;\n</code></pre> <p>3. Re-run PGSync:</p> <pre><code>pgsync -c /path/to/schema.json\n</code></pre> <p>Info</p> <p>If any tables were added or removed from the schema, run <code>bootstrap</code> first before re-indexing.</p>"},{"location":"command-args/","title":"Command Arguments","text":""},{"location":"command-args/#usage","title":"Usage","text":"<pre><code>pgsync [OPTIONS]\n</code></pre>"},{"location":"command-args/#core","title":"Core","text":"Argument Short Description <code>--config</code> <code>-c</code> Path to the schema config file <code>--daemon</code> <code>-d</code> Run continuously (omit for single pass) <code>--bootstrap</code> <code>-b</code> Bootstrap database before syncing <code>--verbose</code> <code>-v</code> Enable verbose output <code>--version</code> Show version info"},{"location":"command-args/#database-connection","title":"Database Connection","text":"Argument Short Description <code>--host</code> <code>-h</code> Override <code>PG_HOST</code> <code>--port</code> <code>-p</code> Override <code>PG_PORT</code> <code>--user</code> <code>-u</code> Override <code>PG_USER</code> <code>--password</code> Prompt for database password"},{"location":"command-args/#ssl","title":"SSL","text":"Argument Description <code>--sslmode</code> SSL mode: <code>disable</code>, <code>allow</code>, <code>prefer</code>, <code>require</code>, <code>verify-ca</code>, <code>verify-full</code> <code>--sslrootcert</code> Override <code>PG_SSLROOTCERT</code>"},{"location":"command-args/#modes","title":"Modes","text":"Argument Short Description <code>--polling</code> Use polling mode instead of logical replication <code>--wal</code> <code>-w</code> WAL consumer mode (no Redis required) <code>--nthreads_polldb</code> <code>-n</code> Number of threads for polling <code>--analyze</code> <code>-a</code> Analyze database schema"},{"location":"command-args/#examples","title":"Examples","text":"<p>First-time setup: <pre><code>pgsync --config schema.json --bootstrap\n</code></pre></p> <p>Run as daemon: <pre><code>pgsync -c schema.json --daemon\n</code></pre></p> <p>Single sync pass: <pre><code>pgsync -c schema.json\n</code></pre></p> <p>With database credentials: <pre><code>pgsync -c schema.json -h localhost -u postgres --password -d\n</code></pre></p> <p>Polling mode with threads: <pre><code>pgsync -c schema.json --polling -n 4 -d\n</code></pre></p> <p>WAL consumer mode: <pre><code>pgsync -c schema.json --wal -d\n</code></pre></p>"},{"location":"env-vars/","title":"Environment Variables","text":"<p>PGSync uses the dotenv module for reading environment variables from a <code>.env</code> file.</p> .env<pre><code>PG_HOST=localhost\nPG_USER=postgres\nPG_PASSWORD=secret\nELASTICSEARCH_HOST=localhost\n</code></pre> <p>Or set them manually:</p> <pre><code>export PG_HOST=localhost\nexport ELASTICSEARCH_HOST=localhost\npgsync -c schema.json\n</code></pre>"},{"location":"env-vars/#general","title":"General","text":"Variable Default Description <code>SCHEMA</code> Path to the application schema config <code>CHECKPOINT_PATH</code> Path to store the checkpoint file <code>QUERY_CHUNK_SIZE</code> 10000 Records to fetch per database query <code>POLL_TIMEOUT</code> 0.1 Poll interval (reduce to increase throughput) <code>POLL_INTERVAL</code> 0.1 Polling interval for polling mode <code>POLLING</code> False Enable polling mode <code>WAL</code> False WAL consumer mode <code>REPLICATION_SLOT_CLEANUP_INTERVAL</code> 180.0 Replication slot cleanup interval (seconds) <code>LOG_INTERVAL</code> 0.5 Stdout log interval (seconds) <code>NUM_WORKERS</code> 2 Number of workers for handling events <code>USE_ASYNC</code> False Enable experimental async mode"},{"location":"env-vars/#database","title":"Database","text":"Variable Default Description <code>PG_HOST</code> localhost Database host <code>PG_PORT</code> 5432 Database port <code>PG_USER</code> Database username (superuser) <code>PG_PASSWORD</code> Database password <code>PG_DRIVER</code> Driver: <code>psycopg2</code> (PostgreSQL) or <code>pymysql</code> (MySQL/MariaDB) <code>PG_SSLMODE</code> SSL mode: <code>disable</code>, <code>allow</code>, <code>prefer</code>, <code>require</code>, <code>verify-ca</code>, <code>verify-full</code> <code>PG_SSLROOTCERT</code> Path to CA certificate file"},{"location":"env-vars/#elasticsearch-opensearch","title":"Elasticsearch / OpenSearch","text":""},{"location":"env-vars/#connection","title":"Connection","text":"Variable Default Description <code>ELASTICSEARCH_SCHEME</code> http Protocol (<code>http</code> or <code>https</code>) <code>ELASTICSEARCH_HOST</code> localhost Host address <code>ELASTICSEARCH_PORT</code> 9200 Port <code>ELASTICSEARCH_USER</code> Username <code>ELASTICSEARCH_PASSWORD</code> Password <code>ELASTICSEARCH_TIMEOUT</code> 10 Request timeout (seconds)"},{"location":"env-vars/#ssltls","title":"SSL/TLS","text":"Variable Default Description <code>ELASTICSEARCH_USE_SSL</code> False Enable SSL <code>ELASTICSEARCH_VERIFY_CERTS</code> True Verify SSL certificates <code>ELASTICSEARCH_SSL_SHOW_WARN</code> False Show SSL verification warnings <code>ELASTICSEARCH_CA_CERTS</code> Path to CA certs <code>ELASTICSEARCH_CLIENT_CERT</code> PEM formatted client certificate <code>ELASTICSEARCH_CLIENT_KEY</code> PEM formatted client key"},{"location":"env-vars/#performance","title":"Performance","text":"Variable Default Description <code>ELASTICSEARCH_CHUNK_SIZE</code> 2000 Documents to index per batch <code>ELASTICSEARCH_MAX_CHUNK_BYTES</code> 104857600 Max request size (bytes, default 100MB) <code>ELASTICSEARCH_THREAD_COUNT</code> 4 Threadpool size for bulk requests <code>ELASTICSEARCH_QUEUE_SIZE</code> 4 Task queue size <code>ELASTICSEARCH_STREAMING_BULK</code> False Enable streaming bulk indexing"},{"location":"env-vars/#retry-error-handling","title":"Retry &amp; Error Handling","text":"Variable Default Description <code>ELASTICSEARCH_MAX_RETRIES</code> 0 Max retries on <code>429</code> errors <code>ELASTICSEARCH_INITIAL_BACKOFF</code> 2 Initial retry backoff (seconds) <code>ELASTICSEARCH_MAX_BACKOFF</code> 600 Max retry backoff (seconds) <code>ELASTICSEARCH_RAISE_ON_EXCEPTION</code> True Propagate exceptions <code>ELASTICSEARCH_RAISE_ON_ERROR</code> True Raise <code>BulkIndexError</code> on failures"},{"location":"env-vars/#aws","title":"AWS","text":"Variable Default Description <code>ELASTICSEARCH_AWS_HOSTED</code> False Using AWS managed service <code>ELASTICSEARCH_AWS_REGION</code> AWS region"},{"location":"env-vars/#api-key-authentication","title":"API Key Authentication","text":"Variable Default Description <code>ELASTICSEARCH_API_KEY_ID</code> API Key ID <code>ELASTICSEARCH_API_KEY</code> API Key"},{"location":"env-vars/#redis-valkey","title":"Redis / Valkey","text":"Variable Default Description <code>REDIS_CHECKPOINT</code> False Store checkpoint in Redis instead of filesystem <code>REDIS_SCHEME</code> redis Connection scheme <code>REDIS_HOST</code> localhost Host address <code>REDIS_PORT</code> 6379 Port <code>REDIS_DB</code> 0 Database number <code>REDIS_USER</code> Username <code>REDIS_AUTH</code> Password <code>REDIS_SOCKET_TIMEOUT</code> 5 Socket timeout (seconds) <code>REDIS_POLL_INTERVAL</code> 0.01 Poll interval <code>REDIS_READ_CHUNK_SIZE</code> 1000 Items to read per batch <code>REDIS_WRITE_CHUNK_SIZE</code> 1000 Items to write per batch"},{"location":"env-vars/#logging-monitoring","title":"Logging &amp; Monitoring","text":"Variable Default Description <code>CONSOLE_LOGGING_HANDLER_MIN_LEVEL</code> Log level: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code> <code>CUSTOM_LOGGING</code> Path to custom logging configuration file <code>FORMAT_WITH_COMMAS</code> True Comma formatted logging output"},{"location":"env-vars/#new-relic","title":"New Relic","text":"Variable Default Description <code>NEW_RELIC_ENVIRONMENT</code> Environment name <code>NEW_RELIC_APP_NAME</code> Application name <code>NEW_RELIC_LOG_LEVEL</code> Log level <code>NEW_RELIC_LICENSE_KEY</code> License key"},{"location":"features/","title":"Features","text":"<p>PGSync focuses on reliability, low overhead, and clean documents for search.</p>"},{"location":"features/#highlights","title":"Highlights","text":"Feature Description Multi-Database Support Works with PostgreSQL (9.6+), MySQL (5.7+), or MariaDB (10.5+) Low Overhead Negligible impact on database performance Transactional Consistency Only committed writes indexed; operations applied in commit order Fault Tolerant No data loss on crashes; resumes from last checkpoint Native JSON Path Returns data directly as PostgreSQL JSON for speed Composite Keys Supports composite primary and foreign keys Deeply Nested Documents Arbitrary depth of related entities supported Customizable Structure Tailor documents to your index and query needs"},{"location":"features/#details","title":"Details","text":""},{"location":"features/#consistency","title":"Consistency","text":"<ul> <li>Only committed transactions appear in Elasticsearch/OpenSearch</li> <li>Operation order (insert \u2192 update \u2192 delete) is preserved based on commit order</li> </ul>"},{"location":"features/#reliability","title":"Reliability","text":"<ul> <li>Designed to avoid data loss if a process crashes or the network drops</li> <li>Recovery resumes from the last successful checkpoint</li> </ul>"},{"location":"features/#data-modeling","title":"Data Modeling","text":"<ul> <li>Composite primary and foreign keys supported</li> <li>Arbitrary-depth relationships (one-to-one, one-to-many, through tables)</li> <li>Extract and map PostgreSQL JSON fields to top-level document fields</li> </ul>"},{"location":"features/#performance","title":"Performance","text":"<ul> <li>Builds documents directly from PostgreSQL JSON to minimize transformation overhead</li> </ul>"},{"location":"features/#compatibility","title":"Compatibility","text":"Database/Service Minimum Version  PostgreSQL 9.6+  MySQL 5.7+  MariaDB 10.5+  Elasticsearch 6.3.1+  OpenSearch 1.3.7+"},{"location":"getting-started/docker/","title":"Docker","text":""},{"location":"getting-started/docker/#running-with-docker","title":"Running with Docker","text":"<p>1. Pull the Docker image:</p> <pre><code>docker pull toluaina1/pgsync:latest\n</code></pre> <p>2. Run the container:</p> <pre><code>docker run --rm -it \\\n  -e REDIS_CHECKPOINT=true \\\n  -e REDIS_HOST=&lt;redis_host_address&gt; \\\n  -e PG_URL=postgres://&lt;username&gt;:&lt;password&gt;@&lt;postgres_host&gt;/&lt;database&gt; \\\n  -e ELASTICSEARCH_URL=http://&lt;elasticsearch_host&gt;:9200 \\\n  -v \"$(pwd)/schema.json:/app/schema.json\" \\\n  toluaina1/pgsync:latest -c schema.json -d -b\n</code></pre>"},{"location":"getting-started/docker/#environment-variables","title":"Environment Variables","text":"<p>Replace the placeholders with your values. See the full list of environment variables.</p> Placeholder Description <code>&lt;redis_host_address&gt;</code> Address of the Redis/Valkey server (e.g., <code>host.docker.internal</code> for local Docker) <code>&lt;username&gt;</code> PostgreSQL username <code>&lt;password&gt;</code> PostgreSQL password <code>&lt;postgres_host&gt;</code> Host address for PostgreSQL (e.g., <code>host.docker.internal</code>) <code>&lt;database&gt;</code> Name of PostgreSQL database <code>&lt;elasticsearch_host&gt;</code> Address of Elasticsearch/OpenSearch (e.g., <code>host.docker.internal</code>)"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#pip-recommended","title":"pip (Recommended)","text":"<pre><code>pip install pgsync\n</code></pre> Using a virtual environment <pre><code>python3 -m venv venv\nsource venv/bin/activate  # Linux/macOS\n# or: venv\\Scripts\\activate  # Windows\npip install pgsync\n</code></pre>"},{"location":"getting-started/installation/#uv","title":"uv","text":"<p>Fast installation with uv:</p> <pre><code>uv tool install pgsync\n</code></pre> <p>Or within a project:</p> <pre><code>uv add pgsync\n</code></pre>"},{"location":"getting-started/installation/#pipx","title":"pipx","text":"<p>Install in an isolated environment:</p> <pre><code>pipx install pgsync\n</code></pre>"},{"location":"getting-started/installation/#docker","title":"Docker","text":"<p>Pull the official image:</p> <pre><code>docker pull toluaina1/pgsync:latest\n</code></pre> <p>See Docker setup for running with Docker.</p>"},{"location":"getting-started/installation/#from-source","title":"From Source","text":"<pre><code>git clone https://github.com/toluaina/pgsync.git\ncd pgsync\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>pgsync --version\n</code></pre> <p>You should see the version number printed.</p> <p>Next Steps</p> <p>Once installed, proceed to Setup to configure your database.</p>"},{"location":"getting-started/running/","title":"Running PGSync","text":""},{"location":"getting-started/running/#bootstrap","title":"Bootstrap","text":"<p>First, you need to bootstrap the database. This is a one-time operation that:</p> <ul> <li>Creates pgsync triggers</li> <li>Creates the logical replication slot</li> </ul> <pre><code>bootstrap --config /path/to/schema.json\n</code></pre>"},{"location":"getting-started/running/#running-modes","title":"Running Modes","text":"<p>There are two modes of running PGSync:</p> <ul> <li>Daemon mode - runs continuously</li> <li>Non-daemon mode - runs a single pass and stops</li> </ul> DaemonNon-daemon <pre><code>pgsync --config /path/to/schema.json --daemon\n</code></pre> <pre><code>pgsync --config /path/to/schema.json\n</code></pre> <p>Info</p> <p>You can also specify the schema config as an environment variable <code>SCHEMA</code> and omit it in the commands above. The next section describes how to provide connection parameters via environment variables.</p>"},{"location":"getting-started/setup/","title":"Setup","text":"Self Hosted AWS RDS/Aurora <p>1. Ensure database user is a superuser (required to query replication slots):</p> <pre><code>SELECT usename FROM pg_user WHERE usesuper = true\n</code></pre> <p>2. Enable logical decoding in postgres.conf:</p> <pre><code>wal_level = logical\n</code></pre> <p>3. Configure replication slots in postgres.conf:</p> <pre><code>max_replication_slots = 1\n</code></pre> <p>Restart Required</p> <p>After changing <code>postgres.conf</code>, restart PostgreSQL for changes to take effect.</p> <p>1. Grant superuser privileges:</p> <pre><code>GRANT rds_superuser TO &lt;username&gt;\n</code></pre> <p>2. Enable logical replication via parameter groups. See AWS documentation.</p> <p>Prevent Log Growth</p> <p>On cloud infrastructure, replication slots can cause WAL logs to grow indefinitely. Set a ceiling using max_slot_wal_keep_size:</p> <pre><code>max_slot_wal_keep_size = 100GB\n</code></pre>"},{"location":"license/","title":"License","text":"<p>MIT License \u2014 a short, permissive license that allows commercial use, modification, distribution, private use, and sublicensing.</p> <p>TL;DR (not legal advice)</p> <ul> <li> Can \u2014 use, copy, modify, merge, publish, distribute, sublicense, and sell copies</li> <li> Must \u2014 keep the copyright notice and permission notice in all copies</li> <li> No warranty \u2014 the software is provided as is; authors are not liable</li> </ul> <p>Copy-paste headers for your source files</p> <pre><code>SPDX-License-Identifier: MIT\nCopyright (c) 2016\u20132025 Tolu Aina\n</code></pre> Full text (authoritative) <pre><code>MIT License\n\nCopyright \u00a9 2016-2025 Tolu Aina\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"reference/","title":"References","text":""},{"location":"reference/#official-resources","title":"Official Resources","text":"Resource Description GitHub Source code, issues, and contributions PyPI Python package installation Docker Hub Container images DigitalOcean Marketplace One-click deployment"},{"location":"reference/#platform-integrations","title":"Platform Integrations","text":"<p>PGSync is recognized by these platforms:</p> Platform Listing PostgreSQL Software Catalogue Elasticsearch Community Integrations OpenSearch Community Projects"},{"location":"reference/#articles-tutorials","title":"Articles &amp; Tutorials","text":"Title Source Postgres to Elasticsearch Streaming Estuary PGSync Introduction: Real-time Integration Tool Hackernoon Real-time Integration of PostgreSQL with Elasticsearch Medium"},{"location":"requirements/","title":"Requirements","text":"<p>PGSync has a small set of runtime dependencies.</p>"},{"location":"requirements/#overview","title":"Overview","text":"Component Minimum Version Required Python 3.9+ Yes"},{"location":"requirements/#source-database-choose-one","title":"Source Database (choose one)","text":"Option Minimum Version  PostgreSQL 9.6+  MySQL 5.7+  MariaDB 10.5+"},{"location":"requirements/#search-backend-choose-one","title":"Search Backend (choose one)","text":"Option Minimum Version  Elasticsearch 6.3.1+  OpenSearch 1.3.7+"},{"location":"requirements/#key-value-store-choose-one","title":"Key-Value Store (choose one)","text":"Option Minimum Version  Redis 3.1.0+  Valkey 7.2.0+"},{"location":"requirements/#configuration","title":"Configuration","text":""},{"location":"requirements/#database-driver","title":"Database Driver","text":"PostgreSQL MySQL /  MariaDB <pre><code>export PG_DRIVER=psycopg2\n</code></pre> Verify installation <pre><code>import psycopg2\nprint(\"psycopg2 OK\")\n</code></pre> <pre><code>export PG_DRIVER=pymysql\n</code></pre> Verify installation <pre><code>import pymysql\nprint(\"PyMySQL OK\")\n</code></pre>"},{"location":"requirements/#search-backend","title":"Search Backend","text":"Elasticsearch OpenSearch <p>Ensure the cluster is reachable from where PGSync runs.</p> <pre><code>curl -s http://localhost:9200 | jq .\n</code></pre> <p>Ensure the cluster is reachable from where PGSync runs.</p> <pre><code>curl -s http://localhost:9200 | jq .\n</code></pre>"},{"location":"requirements/#verify-installation","title":"Verify Installation","text":"<p>Run these commands to verify your environment:</p> <pre><code># Python\npython3 --version\n\n# Database client\npsql --version          # PostgreSQL\nmysql --version         # MySQL/MariaDB\n\n# Key-value store\nredis-cli --version     # Redis\nvalkey-cli --version    # Valkey\n</code></pre> <p>Virtual Environment</p> <p>Always use a virtual environment to isolate PGSync dependencies: <pre><code>python3 -m venv venv\nsource venv/bin/activate\npip install pgsync\n</code></pre></p>"},{"location":"scaling/multiple-workers/","title":"Multiple Workers","text":"<p>Increase throughput by running one or more consumers for the same target schema.</p>"},{"location":"scaling/multiple-workers/#how-it-works","title":"How It Works","text":"<p>1. Run a single producer process:</p> <pre><code>pgsync -c schema.json --producer\n</code></pre> <p>2. Run one or more consumer processes (each in a separate process or machine):</p> <pre><code>pgsync -c schema.json --consumer\npgsync -c schema.json --consumer\npgsync -c schema.json --consumer\n</code></pre> <p>This setup allows multiple consumers to work in parallel, improving overall throughput.</p>"},{"location":"scaling/multiple-workers/#increasing-worker-threads","title":"Increasing Worker Threads","text":"<p>You can also increase the number of workers used for handling requests:</p> <pre><code>pgsync -c schema.json -n 4\npgsync -c schema.json --consumer -n 6\n</code></pre> <p>Info</p> <p>The <code>-n</code> argument does not apply in producer-only mode (<code>pgsync -c schema.json --producer</code>).</p>"},{"location":"scaling/parallel-sync/","title":"Parallel Sync","text":"<p>Parallel Sync significantly improves sync speed by utilizing multiple CPUs/threads. It is particularly useful in environments with high network latency, where PostgreSQL, Elasticsearch/OpenSearch, and PGSync servers run on different networks.</p>"},{"location":"scaling/parallel-sync/#why-use-parallel-sync","title":"Why Use Parallel Sync?","text":"<p>In distributed setups, slow request/response times during database queries can limit sync performance. Even with server-side cursors, delays in fetching the next batch of records can bottleneck the process.</p> <p>Parallel Sync addresses this by running an initial high-speed, parallel sync to populate Elasticsearch/OpenSearch in one iteration. After this, a regular PGSync process can continue to run as a daemon for ongoing sync.</p>"},{"location":"scaling/parallel-sync/#how-it-works","title":"How It Works","text":"<p>PGSync leverages PostgreSQL's internal <code>ctid</code> system column, which uniquely identifies rows based on their position in a table (page and row number).</p> <ul> <li>The sync process paginates records using <code>ctid</code>, distributing work evenly across available CPUs/threads</li> <li>Each worker thread processes a \"chunk\" of data in parallel, using efficient filtered queries based on page and row numbers</li> <li>Bulk inserts to Elasticsearch/OpenSearch are executed concurrently, maximizing throughput</li> </ul>"},{"location":"scaling/parallel-sync/#execution-modes","title":"Execution Modes","text":"<p>Parallel Sync supports multiple execution modes to match your system's architecture and performance needs.</p> <pre><code>parallel_sync -c schema.json -m multiprocess\n</code></pre> <p>Available Modes:</p> Mode Description <code>synchronous</code> Runs in single-threaded, sequential mode (baseline behavior) <code>multithreaded</code> Uses multiple threads within a single process for parallel sync <code>multiprocess</code> Spawns multiple processes to perform sync in parallel <code>multithreaded_async</code> Combines multithreading with asynchronous I/O for improved concurrency <code>multiprocess_async</code> Combines multiple processes with asynchronous I/O for maximum parallelism and efficiency"},{"location":"schema/","title":"Schema Definition","text":"<p>The schema file defines how to map your database tables to Elasticsearch/OpenSearch documents.</p>"},{"location":"schema/#basic-example","title":"Basic Example","text":"<pre><code>[\n  {\n    \"database\": \"mydb\",\n    \"index\": \"books\",\n    \"nodes\": {\n      \"table\": \"book\",\n      \"columns\": [\"isbn\", \"title\"],\n      \"children\": [\n        {\n          \"table\": \"author\",\n          \"columns\": [\"name\"]\n        }\n      ]\n    }\n  }\n]\n</code></pre> Full Schema Reference <pre><code>[\n  {\n    \"database\": \"&lt;database name&gt;\",\n    \"index\": \"&lt;index name&gt;\",\n    \"setting\": { },\n    \"plugins\": [\"&lt;Plugin A&gt;\", \"&lt;Plugin B&gt;\"],\n    \"pipeline\": \"&lt;pipeline&gt;\",\n    \"routing\": \"&lt;routing&gt;\",\n    \"nodes\": {\n      \"table\": \"&lt;table name&gt;\",\n      \"schema\": \"&lt;schema name&gt;\",\n      \"columns\": [\"&lt;column 1&gt;\", \"&lt;column 2&gt;\"],\n      \"label\": \"&lt;label&gt;\",\n      \"children\": [\n        {\n          \"table\": \"&lt;child table&gt;\",\n          \"columns\": [\"&lt;column&gt;\"],\n          \"label\": \"&lt;label&gt;\",\n          \"relationship\": {\n            \"variant\": \"object | scalar\",\n            \"type\": \"one_to_one | one_to_many\",\n            \"through_tables\": [\"&lt;junction table&gt;\"]\n          },\n          \"transform\": {\n            \"rename\": { },\n            \"mapping\": { },\n            \"concat\": { }\n          }\n        }\n      ]\n    }\n  }\n]\n</code></pre>"},{"location":"schema/#root-properties","title":"Root Properties","text":"Property Required Description <code>database</code> Yes Database name <code>index</code> No Elasticsearch/OpenSearch index name (defaults to database name) <code>nodes</code> Yes Root node defining the document structure <code>plugins</code> No List of plugins to apply <code>pipeline</code> No Elasticsearch ingest pipeline <code>routing</code> No Elasticsearch routing field <code>setting</code> No Elasticsearch index settings Index Settings <pre><code>{\n  \"setting\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"ngram_analyzer\": {\n          \"filter\": [\"lowercase\"],\n          \"type\": \"custom\",\n          \"tokenizer\": \"ngram_tokenizer\"\n        }\n      },\n      \"tokenizer\": {\n        \"ngram_tokenizer\": {\n          \"token_chars\": [\"letter\", \"digit\"],\n          \"min_gram\": \"2\",\n          \"max_gram\": \"10\",\n          \"type\": \"ngram\"\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"schema/#node-properties","title":"Node Properties","text":"Property Required Description <code>table</code> Yes Database table name <code>schema</code> No Database schema (defaults to <code>public</code>) <code>columns</code> No Columns to include (defaults to all) <code>label</code> No Field name in output document (defaults to table name) <code>children</code> No Child nodes (nested documents) <code>transform</code> No Transform operations <code>relationship</code> No Relationship configuration (for child nodes)"},{"location":"schema/#relationship","title":"Relationship","text":"<p>Defines how parent and child nodes are related.</p> Property Values Description <code>variant</code> <code>object</code>, <code>scalar</code> Output format <code>type</code> <code>one_to_one</code>, <code>one_to_many</code> Relationship cardinality <code>through_tables</code> <code>[\"table_name\"]</code> Junction tables for many-to-many"},{"location":"schema/#variant-examples","title":"Variant Examples","text":"objectscalar <p>Returns the full object: <pre><code>{\n  \"author\": {\n    \"id\": 1,\n    \"name\": \"George Orwell\"\n  }\n}\n</code></pre></p> <p>Returns only the value(s): <pre><code>{\n  \"author\": [\"George Orwell\", \"Aldous Huxley\"]\n}\n</code></pre></p>"},{"location":"schema/#transform","title":"Transform","text":"<p>Transform operations modify the output document.</p>"},{"location":"schema/#rename","title":"<code>rename</code>","text":"<p>Rename columns in the output:</p> <pre><code>\"transform\": {\n  \"rename\": {\n    \"isbn\": \"book_isbn\",\n    \"title\": \"book_title\"\n  }\n}\n</code></pre>"},{"location":"schema/#mapping","title":"<code>mapping</code>","text":"<p>Specify Elasticsearch field mappings:</p> <pre><code>\"transform\": {\n  \"mapping\": {\n    \"isbn\": { \"type\": \"keyword\" },\n    \"title\": { \"type\": \"text\" },\n    \"price\": { \"type\": \"float\" }\n  }\n}\n</code></pre>"},{"location":"schema/#concat","title":"<code>concat</code>","text":"<p>Concatenate columns into a new field:</p> <pre><code>\"transform\": {\n  \"concat\": {\n    \"columns\": [\"first_name\", \"last_name\"],\n    \"destination\": \"full_name\",\n    \"delimiter\": \" \"\n  }\n}\n</code></pre> <p>Re-indexing Required</p> <p>Changing the schema changes the document structure. You must re-index after schema changes.</p>"},{"location":"tutorial/json-fields/","title":"JSON Fields","text":"<p>PGSync supports Postgres JSON and JSONB operators. This allows you to extract data within JSON fields.</p> <p>These operators are defined here</p> <p>For example, given a Postgres JSON field called <code>doc</code></p> <pre><code>{\n    \"a\": {\n        \"b\": {\n            \"c\": [0, 1, 2, 3, 4]\n        }\n    },\n    \"x\": [\n        {\n            \"y\": 0,\n            \"z\": 5\n        },\n        {\n            \"y\": 1,\n            \"z\": 6\n        }\n    ]\n}\n</code></pre> <p>To extract the fourth element of the <code>{a, b, c}</code> path, define this schema</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"schema\": \"my_book_library\",\n            \"columns\": [\n                \"doc#&gt;{a,b,c}-&gt;4\"\n            ]\n        }\n    }\n]\n</code></pre> <p>We can define this JSON schema, to get the first array element of field <code>x</code>.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"schema\": \"my_book_library\",\n            \"columns\": [\n                \"doc-&gt;x-&gt;0\"\n            ]\n        }\n    }\n]\n</code></pre> <p>Info</p> <p><code>doc</code> is the field name in the database</p>"},{"location":"tutorial/multiple-schemas-in-single-config/","title":"Multiple Schemas in a Single Config","text":"<p>You can declare multiple schemas in the same config file to sync multiple tables into different Elasticsearch/OpenSearch indices.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book_index\",\n        \"nodes\": {\n            \"table\": \"book\"\n        }\n    },\n    {\n        \"database\": \"book\",\n        \"index\": \"author_index\",\n        \"nodes\": {\n            \"table\": \"author\"\n        }\n    }\n]\n</code></pre>"},{"location":"tutorial/plugins/","title":"Plugins","text":"<p>Plugins allow you to alter a document right before indexing. This is useful for applying custom transformations and offers greater flexibility, though it requires some development effort.</p> <p>Plugins are currently supported only in the Python Language.</p> <p>For example, imagine you had a user profile database with <code>firstname</code> and  <code>lastname</code> fields and generating the Elasticsearch/OpenSearch doc below.</p> <pre><code>{\n    \"firstname\": \"feng\",\n    \"lastname\": \"shui\"\n}\n</code></pre> <p>we can create a plugin to add a <code>fullname</code> field to the document  right before indexing. </p> <p>Create a \"plugins\" directory and add it to your <code>PYTHONPATH</code>.</p> <p>The <code>PYTHONPATH</code> should point to the parent directory containing your \"plugins\" folder.</p> <p>e.g:</p> <p><code>export PYTHONPATH=$PYTHONPATH:/path/to/myplugindir</code></p> <p>Make sure you have created an empty init module inside the \"plugins\" directory i.e <code>plugins/__init__.py</code></p> <p>Create a plugin module - fullnameplugin.py inside the \"plugins\" directory and  add the code below:</p> <pre><code>from pgsync import plugin\n\n\nclass FullnamePlugin(plugin.Plugin):\n    name = 'Fullname'\n\n    def transform(self, doc, **kwargs):\n        firstname = doc['firstname']\n        lastname = doc['lastname']\n        doc['fullname'] = f'{firstname} {lastname}'\n        return doc\n</code></pre> <p>Your plugins directory layout should look like this:</p> <ul> <li><code>plugins/fullnameplugin.py</code></li> <li><code>plugins/__init__.py</code></li> </ul> <p>Then simply activate the plugin by adding it to the list of plugins in the schema.json</p> <pre><code>[\n    {\n        \"database\": \"users\",\n        \"index\": \"users\",\n        \"plugins\": [\"Fullname\"],\n        \"nodes\": {\n            \"table\": \"profile\"\n        }\n    }\n]\n</code></pre> <p>To get this document in Elasticsearch/OpenSearch</p> <pre><code>{\n    \"firstname\": \"feng\",\n    \"lastname\": \"shui\",\n    \"fullname\": \"feng shui\"\n}\n</code></pre> <p>Info</p> <p>Plugin names are case sensitive</p>"},{"location":"tutorial/relationship-with-object-variant/","title":"Relationship with Object Variant","text":"<p>Each child node can have only one direct parent. You can specify the relationship between a parent and child node using the <code>relationship</code> property.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"id\",\n                        \"name\"\n                    ],\n                    \"relationship\": {\n                        \"variant\": \"object\",\n                        \"type\": \"one_to_one\"\n                    },\n                }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"publisher\": {\n          \"id\": 1,\n          \"name\": \"Oxford Press\"\n      }\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"publisher\": {\n          \"id\": 2,\n          \"name\": \"Penguin Books\"\n      }\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"publisher\": {\n          \"id\": 3,\n          \"name\": \"Pearson Press\"\n      }\n  }\n]\n</code></pre> <p>Info</p> <p>A relationship must include both a <code>variant</code> and a <code>type</code> attribute</p>"},{"location":"tutorial/relationship-with-one-to-many-type/","title":"Relationship with One-to-Many Type","text":"<p>Each child node can have only one direct parent. You can specify the relationship between a parent and child node using the <code>relationship</code> property.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"id\",\n                        \"name\"\n                    ],\n                    \"relationship\": {\n                        \"variant\": \"object\",\n                        \"type\": \"one_to_many\"\n                    },\n                }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"publisher\": [\n          {\n            \"id\": 1,\n            \"name\": \"Oxford Press\"\n          }\n       ]\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"publisher\": [\n          {\n            \"id\": 2,\n            \"name\": \"Penguin Books\"\n          }\n       ]\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"publisher\": [\n          {\n            \"id\": 3,\n            \"name\": \"Pearson Press\"\n          }\n       ]\n  }\n]\n</code></pre> <p>Info</p> <p>A relationship must include both a <code>variant</code> and a <code>type</code> attribute</p>"},{"location":"tutorial/relationship-with-one-to-one-type/","title":"Relationship with One-to-One Type","text":"<p>Each child node can have only one direct parent. You can specify the relationship between a parent and child node using the <code>relationship</code> property.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"id\",\n                        \"name\"\n                    ],\n                    \"relationship\": {\n                        \"variant\": \"object\",\n                        \"type\": \"one_to_one\"\n                    },\n                }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"publisher\": {\n          \"id\": 1,\n          \"name\": \"Oxford Press\"\n      }\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"publisher\": {\n          \"id\": 2,\n          \"name\": \"Penguin Books\"\n      }\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"publisher\": {\n          \"id\": 3,\n          \"name\": \"Pearson Press\"\n      }\n  }\n]\n</code></pre> <p>Info</p> <p>A relationship must include both a <code>variant</code> and a <code>type</code> attribute</p>"},{"location":"tutorial/relationship-with-scalar-variant/","title":"Relationship with Scalar Variant","text":"<p>Each child node can have only one direct parent. You can specify the relationship between a parent and child node using the <code>relationship</code> property.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"name\"\n                    ],\n                    \"relationship\": {\n                        \"variant\": \"scalar\",\n                        \"type\": \"one_to_one\"\n                    },\n                }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"publisher\": \"Oxford Press\"\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"publisher\": \"Penguin Books\"\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"publisher\":  \"Pearson Press\"\n  }\n]\n</code></pre> <p>Info</p> <p>A relationship must include both a <code>variant</code> and a <code>type</code> attribute</p>"},{"location":"tutorial/relationship-with-through-tables/","title":"Relationship with Through Tables","text":"<p>Each child node can have only one direct parent. You can specify the relationship between a parent and child node using the <code>relationship</code> property.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"columns\": [\n                \"isbn\",\n                \"title\",\n                \"description\"\n            ],\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"id\", \"name\"\n                    ],\n                    \"relationship\": {\n                        \"type\": \"one_to_many\",\n                        \"variant\": \"object\",\n                        \"through_tables\": [\n                            \"book_author\"\n                        ]\n                    }\n                 }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"author\": [\n          {\n            \"id\": 1,\n            \"name\": \"Roald Dahl\"\n          }\n       ]\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"author\": [\n          {\n            \"id\": 2,\n            \"name\": \"Haruki Murakami\"\n          },\n          {\n            \"id\": 3,\n            \"name\": \"Philip Gabriel\"\n          }\n       ]\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"author\": [\n          {\n            \"id\": 4,\n            \"name\": \"George Orwell\"\n          }\n       ]\n  }\n]\n</code></pre> <p>Info</p> <p>A relationship must include both a <code>variant</code> and a <code>type</code> attribute</p>"},{"location":"tutorial/relationship-with-user-defined-foreign-key/","title":"Relationship with User-Defined Foreign Key","text":"<p>You can specify the relationship foreign key as a property on the <code>relationship</code>.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"id\",\n                        \"name\"\n                    ],\n                    \"relationship\": {\n                        \"variant\": \"object\",\n                        \"type\": \"one_to_one\",\n                        \"foreign_key\": {\n                            \"child\": [\"id\"],\n                            \"parent\": [\"parent_id\"]\n                        }\n                    },\n                }\n            ]\n        }\n    }\n]\n</code></pre>"},{"location":"tutorial/selecting-schema/","title":"Selecting Schema","text":"<p>Postgres supports having multiple schemas in the same database. You can select an alternative schema using the node <code>schema</code> attribute.</p> <p>The default schema is the <code>public</code> schema.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"schema\": \"my_book_library\",\n            \"columns\": [\n                \"isbn\",\n                \"title\"\n            ]\n        }\n    }\n]\n</code></pre>"},{"location":"tutorial/table-with-multiple-children/","title":"Table with Multiple Children","text":"<p>What if we added a new table <code>publisher</code>?</p> <p>Publisher</p> id (PK) name 1 Oxford Press 2 Penguin Books 3 Pearson Press <p>and we added <code>publisher_id</code> as a foreign key to the Book table:</p> <p>Book</p> isbn (PK) title description publisher_id (FK) 9785811243570 Charlie and the chocolate factory Willy Wonka\u2019s famous chocolate factory is opening at last! 1 9788374950978 Kafka on the Shore Kafka on the Shore is a 2002 novel by Japanese author Haruki Murakami. 2 9781471331435 1984 1984 was George Orwell\u2019s chilling prophecy about the dystopian future. 3 <p>We can simply define this JSON schema where the book table is still the pivot table.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"columns\": [\n                \"isbn\",\n                \"title\",\n                \"description\"\n            ],\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"columns\": [\n                        \"name\"\n                    ]\n                },\n                {\n                    \"table\": \"publisher\",\n                    \"columns\": [\n                        \"name\",\n                        \"id\"\n                    ]\n                }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"description\": \"Willy Wonka\u2019s famous chocolate factory is opening at last!\",\n      \"author\": [\"Roald Dahl\"],\n      \"publisher\": \"Oxford Press\"\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"description\": \"Kafka on the Shore is a 2002 novel by Japanese author Haruki Murakami\",\n      \"author\": [\"Haruki Murakami\", \"Philip Gabriel\"],\n      \"publisher\": \"Penguin Books\"\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"description\": \"1984 was George Orwell\u2019s chilling prophecy about the dystopian future\",\n      \"author\": [\"George Orwell\"],\n      \"publisher\": \"Pearson Press\"\n  }\n]\n</code></pre>"},{"location":"tutorial/table-with-single-child-node/","title":"Table with Single Child Node","text":"<p>Consider this example of a Book library database.</p> <p>Book</p> isbn (PK) title description 9785811243570 Charlie and the chocolate factory Willy Wonka\u2019s famous chocolate factory is opening at last! 9788374950978 Kafka on the Shore Kafka on the Shore is a 2002 novel by Japanese author Haruki Murakami. 9781471331435 1984 1984 was George Orwell\u2019s chilling prophecy about the dystopian future. <p>Author</p> id (PK) name 1 Roald Dahl 2 Haruki Murakami 3 Philip Gabriel 4 George Orwell <p>BookAuthor</p> id (PK) book_isbn (FK) author_id (FK) 1 9785811243570 1 2 9788374950978 2 3 9788374950978 3 4 9781471331435 4 <p>With PGSync, we can simply define this JSON schema where the book table is the pivot. A pivot table indicates the root of your document.</p> <pre><code>{\n    \"table\": \"book\",\n    \"columns\": [\n        \"isbn\",\n        \"title\",\n        \"description\"\n    ],\n    \"children\": [\n        {\n            \"table\": \"author\",\n            \"columns\": [\n                \"name\"\n            ]\n        }\n    ]\n}\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"description\": \"Willy Wonka\u2019s famous chocolate factory is opening at last!\",\n      \"author\": [\"Roald Dahl\"]\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"description\": \"Kafka on the Shore is a 2002 novel by Japanese author Haruki Murakami\",\n      \"author\": [\"Haruki Murakami\", \"Philip Gabriel\"]\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"description\": \"1984 was George Orwell\u2019s chilling prophecy about the dystopian future\",\n      \"author\": [\"George Orwell\"]\n  }\n]\n</code></pre> <p>Behind the scenes, PGSync is generating advanced queries for you such as.</p> <pre><code>SELECT \n       JSON_BUILD_OBJECT(\n          'isbn', book_1.isbn, \n          'title', book_1.title, \n          'description', book_1.description,\n          'authors', anon_1.authors\n       ) AS \"JSON_BUILD_OBJECT_1\",\n       book_1.id\nFROM book AS book_1\nLEFT OUTER JOIN\n  (SELECT \n          JSON_AGG(anon_2.anon) AS authors,\n          book_author_1.book_isbn AS book_isbn\n   FROM book_author AS book_author_1\n   LEFT OUTER JOIN\n     (SELECT \n             author_1.name AS anon,\n             author_1.id AS id\n      FROM author AS author_1) AS anon_2 ON anon_2.id = book_author_1.author_id\n   GROUP BY book_author_1.book_isbn) AS anon_1 ON anon_1.book_isbn = book_1.isbn\n</code></pre>"},{"location":"tutorial/transform-nodes/","title":"Transform Nodes","text":"<p>Transform nodes allow you to change the output of the document type.</p>"},{"location":"tutorial/transform-nodes/#rename","title":"<code>rename</code>","text":"<p>We can simply define this JSON schema.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"columns\": [\n                \"isbn\",\n                \"title\"\n            ],\n            \"transform\": {\n                \"rename\": {\n                    \"isbn\": \"book_isbn\",\n                    \"title\": \"book_title\"\n                }\n            }\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n    {\n        \"book_isbn\": \"9785811243570\",\n        \"book_title\": \"Charlie and the chocolate factory\"\n    },\n    {\n        \"book_isbn\": \"9788374950978\",\n        \"book_title\": \"Kafka on the Shore\"\n    },\n    {\n        \"book_isbn\": \"9781471331435\",\n        \"book_title\": \"1984\"\n    }\n]\n</code></pre>"},{"location":"tutorial/transform-nodes/#mapping","title":"<code>mapping</code>","text":"<p>You can specify the data type for an Elasticsearch/OpenSearch field in the schema.</p> <p>You can find the list of supported data types here</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"columns\": [\n                \"isbn\",\n                \"title\"\n            ],\n            \"transform\": {\n                \"mapping\": {\n                    \"id\": {\n                        \"type\": \"long\"\n                    },\n                    \"isbn\": {\n                        \"type\": \"long\"\n                    },\n                    \"title\": {\n                        \"type\": \"keyword\"\n                    }\n                }\n            }\n        }\n    }\n]\n</code></pre>"},{"location":"tutorial/transform-nodes/#concat","title":"<code>concat</code>","text":"<p>You can concatenate multiple columns into a single field with an optional delimiter.</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"columns\": [\n                \"title\",\n                \"firstname\",\n                \"lastname\"\n            ],\n            \"transform\": {\n                \"concat\": {\n                    \"columns\": [\"title\", \"firstname\", \"lastname\"],\n                    \"destination\": \"fullname\",\n                    \"delimiter\": \"-\"\n                }\n            }\n        }\n    }\n]\n</code></pre>"},{"location":"tutorial/using-labels/","title":"Using Labels","text":"<p>Labels are used to control the output of the document node. Define this JSON schema:</p> <pre><code>[\n    {\n        \"database\": \"book\",\n        \"index\": \"book\",\n        \"nodes\": {\n            \"table\": \"book\",\n            \"columns\": [\n                \"isbn\",\n                \"title\"\n            ],\n            \"children\": [\n                {\n                    \"table\": \"author\",\n                    \"label\": \"authors\",\n                    \"columns\": [\n                        \"name\"\n                    ]\n                }\n            ]\n        }\n    }\n]\n</code></pre> <p>To get this document structure in Elasticsearch/OpenSearch</p> <pre><code>[\n  {\n      \"isbn\": \"9785811243570\",\n      \"title\": \"Charlie and the chocolate factory\",\n      \"authors\": [\"Roald Dahl\"]\n  },\n  {\n      \"isbn\": \"9788374950978\",\n      \"title\": \"Kafka on the Shore\",\n      \"authors\": [\"Haruki Murakami\", \"Philip Gabriel\"]\n  },\n  {\n      \"isbn\": \"9781471331435\",\n      \"title\": \"1984\",\n      \"authors\": [\"George Orwell\"]\n  }\n]\n</code></pre>"}]}